{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2A)\n",
    "\n",
    "Implement an logistic discrimination classifier and use the training data to train the classifier.\n",
    "\n",
    "You should use stochastic gradient descent and implement it in Python. Plot the training error as a function of\n",
    "epochs, and report the accuracy on the training set. \n",
    "\n",
    "Try different learning rates for the gradient descent\n",
    "and explain what you observe for these different values. Optional, it may help the learning process if the\n",
    "data is shuffled (songs are fed to the classifier in random order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load in the arrays from problem-1\n",
    "X_train = np.load('X_train.npy', allow_pickle=True)\n",
    "X_test = np.load('X_test.npy', allow_pickle=True)\n",
    "y_train = np.load('y_train.npy', allow_pickle=True)\n",
    "y_test = np.load('y_test.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_regression(X, y, learning_rate=0.01, epochs=100):\n",
    "  \n",
    "    # Get the number of samples and features\n",
    "    number_of_samples, number_of_features = X.shape\n",
    "  \n",
    "    # Initialize weights and bias\n",
    "    w = np.zeros(number_of_features)  # weights should have the shape (number_of_features,)\n",
    "    b = 0  # bias is a scalar\n",
    "  \n",
    "    for epoch in range(epochs):\n",
    "        # Variable to keep track of total loss for each iteration over the dataset\n",
    "        total_loss = 0\n",
    "        \n",
    "    \n",
    "    \n",
    "        # Shuffle the data at the start of each epoch\n",
    "        indices = np.random.permutation(number_of_samples)\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "    \n",
    "        # Loop to update the Gradient Descent using SGD\n",
    "        for i in range(number_of_samples):\n",
    "            xi = X_shuffled[i]  # feature vector for sample i\n",
    "            yi = y_shuffled[i]  # true label for sample i\n",
    "            \n",
    "            # Compute the weighted sum (linear combination of features and weights)\n",
    "            z = np.dot(xi, w) + b  # z is the weighted sum for the current sample\n",
    "\n",
    "            # Pass the weighted sum to the sigmoid function to get the predicted probability\n",
    "            # y_pred = sigmoid(z)\n",
    "        \n",
    "\n",
    "\n",
    "# Assuming X_train and y_train are already defined\n",
    "logistic_regression(X=X_train, y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
